{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Final Project - Fine Tuning Legal-Pegasus for Summary Generation 2.ipynb","provenance":[{"file_id":"17LQ-tZx-fwd9tYuq3Xl4KcDcBSrpHZ-c","timestamp":1621997194296},{"file_id":"13t710ZSL4BU0uRVx6KwX_d4SBmwBUyoi","timestamp":1621816451576},{"file_id":"13qzkIUYMD0-vKcK-z490d7mBcPpJOdqb","timestamp":1621810510287}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"0db359f52adc4bbe948958097f43f706":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c323a02c7ea49aa8bcec4db59c0bac7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b5f6fecc857247f398b02f6c273fefa8","IPY_MODEL_ffdf7a9940c24c4d9f71b0aab506f138"]}},"9c323a02c7ea49aa8bcec4db59c0bac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5f6fecc857247f398b02f6c273fefa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2375a1ce655a42fda70975ba382b5ed6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1328,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1328,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e76fac801d64e828c43b5bd30c3d0e6"}},"ffdf7a9940c24c4d9f71b0aab506f138":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_576ad34ca48146598da48bb190efa4c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.33k/1.33k [00:03&lt;00:00, 401B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d57ff39389c4e44a0d0a8cf145d0f1f"}},"2375a1ce655a42fda70975ba382b5ed6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e76fac801d64e828c43b5bd30c3d0e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"576ad34ca48146598da48bb190efa4c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1d57ff39389c4e44a0d0a8cf145d0f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"390bb3b38df14966a95160af160d2050":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_194c61711e354b23b6868dee03137fe9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c65098b7efd84aa2b94335c3458abc5c","IPY_MODEL_08e1c3beaccc4a43b6f09cc30a2190fc"]}},"194c61711e354b23b6868dee03137fe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c65098b7efd84aa2b94335c3458abc5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_030f3ce3cac44750abbd38195f3aca2f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1912529,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1912529,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e8ad7ad342c4d909b9ed38dab03f000"}},"08e1c3beaccc4a43b6f09cc30a2190fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_953e7aaa02c649c887c52b2fa74839bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.91M/1.91M [00:02&lt;00:00, 846kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b31a1a7e185456e976d38a9abd5e7de"}},"030f3ce3cac44750abbd38195f3aca2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e8ad7ad342c4d909b9ed38dab03f000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"953e7aaa02c649c887c52b2fa74839bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9b31a1a7e185456e976d38a9abd5e7de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc0010509409426fb17e941d56019b76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_edf49e2810ae45e3a14cf82fc0920ed1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2205be2c4e7c47628a74a3c1487f1684","IPY_MODEL_4e786a3698204973a28221a28dc36540"]}},"edf49e2810ae45e3a14cf82fc0920ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2205be2c4e7c47628a74a3c1487f1684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f1922313dd4648f08b6991e5c967905e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1341,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1341,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba84786fa17b44edaebb2de50503cd1c"}},"4e786a3698204973a28221a28dc36540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8350cf8958240ffba427e5f4d67b961","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34k/1.34k [00:00&lt;00:00, 2.10kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c79ab82798248db8d827d5c0697e5e6"}},"f1922313dd4648f08b6991e5c967905e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ba84786fa17b44edaebb2de50503cd1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8350cf8958240ffba427e5f4d67b961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6c79ab82798248db8d827d5c0697e5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36e2f9d172f54aa199bf6fc94c3dc164":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d10be282455b417caf3cc0cd610ed4ac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c9c587ca3cc4b1f8a28bb80ad9eb512","IPY_MODEL_073e69534b4f42de8823e0e7c8dd3f55"]}},"d10be282455b417caf3cc0cd610ed4ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c9c587ca3cc4b1f8a28bb80ad9eb512":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76856ac9acc54a2cbc37dd5e53a9de38","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9d51d743aaa48b2971f7ef6a8bea9db"}},"073e69534b4f42de8823e0e7c8dd3f55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aee5e212734a446d928228fc05eec2c9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.51k/1.51k [00:00&lt;00:00, 5.24kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0f99d805790466384f511457353d02e"}},"76856ac9acc54a2cbc37dd5e53a9de38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9d51d743aaa48b2971f7ef6a8bea9db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aee5e212734a446d928228fc05eec2c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0f99d805790466384f511457353d02e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e1bef79e65a48e385b74990b9c0b1de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e9c31472af94dc0af3bdbd8ca2640ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a40afcde00d43b0bb81ca30c3414f25","IPY_MODEL_64806cc694a649b7a40a289ccffdaee8"]}},"0e9c31472af94dc0af3bdbd8ca2640ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a40afcde00d43b0bb81ca30c3414f25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4fe22acd343f445da93ab3e91e34b1ec","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2283841687,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2283841687,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2573ef84624e4b05beb104ab8819c709"}},"64806cc694a649b7a40a289ccffdaee8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f21a0e72d8ff4ec288c1f0766c075c34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.28G/2.28G [01:15&lt;00:00, 30.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77968d3458b640a882350f290b7bd41e"}},"4fe22acd343f445da93ab3e91e34b1ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2573ef84624e4b05beb104ab8819c709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f21a0e72d8ff4ec288c1f0766c075c34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"77968d3458b640a882350f290b7bd41e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63bc6624ab404bf7949a2a31dcdbe9c7":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_688e9dbac19842748dbe7d8edbe8ff81","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a72c08ec2914047bad85b36bbcb96de","IPY_MODEL_b423f4f655784b9cb3ed7c1d89d65f33"]}},"688e9dbac19842748dbe7d8edbe8ff81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a72c08ec2914047bad85b36bbcb96de":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_e0b4114b03f246b09813df01f3d3d0f0","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.28MB of 1.28MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6def35e90c1404da021b40fc09ef93d"}},"b423f4f655784b9cb3ed7c1d89d65f33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8652d66f21364a7386715df31ac8e9de","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7364e3848b234801be85bf19070f3b29"}},"e0b4114b03f246b09813df01f3d3d0f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6def35e90c1404da021b40fc09ef93d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8652d66f21364a7386715df31ac8e9de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7364e3848b234801be85bf19070f3b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60ae3c9f6bda4c6a86e624bde2ab7eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc2dff9dbac543af9d7e990e83ba9392","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42a7eca621384ae0907b2414e9ac69fb","IPY_MODEL_adee1dec79fa4f65a2cd7c09bd4379c7"]}},"fc2dff9dbac543af9d7e990e83ba9392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42a7eca621384ae0907b2414e9ac69fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8813d62880be42acbe1a83e55a7c2a44","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":48,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":48,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e14d8d26d77f40f4847e039593803ae7"}},"adee1dec79fa4f65a2cd7c09bd4379c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89f9de024e5442ffb494c1cbb3d1757c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 58/? [00:25&lt;00:00,  2.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8f13840fb064839a0511a6a85f730db"}},"8813d62880be42acbe1a83e55a7c2a44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e14d8d26d77f40f4847e039593803ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89f9de024e5442ffb494c1cbb3d1757c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8f13840fb064839a0511a6a85f730db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5166075291b74bfc9748e19c5bec45bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_abd4e0f16b374b51ae0a2a25ae04b2d6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed208c807e2141b3b5899d61bd00f948","IPY_MODEL_aabde2074eba41b5bf01658bc1e06f62"]}},"abd4e0f16b374b51ae0a2a25ae04b2d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed208c807e2141b3b5899d61bd00f948":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a5999242b67c41e787309bd95d07a461","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":48,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":48,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ddd4ef28407647ff967c7d71d494520a"}},"aabde2074eba41b5bf01658bc1e06f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_443f319497f040f7beb141cc3b673f14","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 58/? [00:26&lt;00:00,  1.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f86a48609a444f0b79653a80a5437ae"}},"a5999242b67c41e787309bd95d07a461":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ddd4ef28407647ff967c7d71d494520a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"443f319497f040f7beb141cc3b673f14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f86a48609a444f0b79653a80a5437ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"y9d3zWDiq-E2"},"source":["# Fine Tuning Pegasus - Legal Summarization"]},{"cell_type":"code","metadata":{"id":"WD_vnyLXZQzD","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622517222379,"user_tz":240,"elapsed":26539,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"9cb68471-541e-40b2-f8f4-028faf645a16"},"source":["# Install the necessary libraries here\n","\n","!pip install transformers -q\n","!pip install wandb\n","\n","!pip install rouge-score\n","!pip install shap\n","!pip install sentencepiece\n","\n","# Code for TPU packages install\n","# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.3MB 7.3MB/s \n","\u001b[K     |████████████████████████████████| 901kB 42.2MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 51.2MB/s \n","\u001b[?25hCollecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/48/b199e2b3b341ac842108c5db4956091dd75d961cfa77aceb033e99cac20f/wandb-0.10.31-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 8.2MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 46.5MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n","\u001b[K     |████████████████████████████████| 174kB 50.3MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: pathtools, subprocess32\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=43b5e08b9ae8df28c3852f01891b9559db0fd58cb968c3a96209b31ae0d9e230\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=2b159c7b6ba25857c259f4f3c6246e8bb60fb812be0ebc092664e910908df47a\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","Successfully built pathtools subprocess32\n","Installing collected packages: shortuuid, sentry-sdk, docker-pycreds, pathtools, configparser, subprocess32, smmap, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.31\n","Collecting rouge-score\n","  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n","Collecting shap\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n","\u001b[K     |████████████████████████████████| 358kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n","Collecting slicer==0.0.7\n","  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (56.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n","Building wheels for collected packages: shap\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491624 sha256=63024f51abbe93ceb7b63388385d08639fe8873588ef86696419d369f08dd346\n","  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n","Successfully built shap\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.39.0 slicer-0.0.7\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 6.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtP33PRprQa5","executionInfo":{"status":"ok","timestamp":1622517237046,"user_tz":240,"elapsed":11784,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"2a533deb-5e14-4c19-becf-04b3a36b30fc"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","import os\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzM1_ykHaFur","executionInfo":{"status":"ok","timestamp":1622517248852,"user_tz":240,"elapsed":10610,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"badeb460-fa75-417d-9681-c58f13ec5dbb"},"source":["\n","# os.chdir(\"D:/Datasets/453_NLP_Final_Project\")\n","#os.environ['TRANSFORMERS_CACHE'] = 'D:/huggingface/transformers'\n","#os.environ['HF_DATASETS_CACHE'] = 'D:/huggingface/datasets'\n","#os.environ['HF_METRICS_CACHE'] = 'D:/huggingface/metrics'\n","#os.environ['HF_MODULE_CACHE'] = 'D:/huggingface/modules'\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Importing the transformers\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# WandB – Import the wandb library\n","import wandb\n","import time\n","from rouge_score import rouge_scorer\n","import shap\n","import sentencepiece\n","\n","# Project Parameters\n","filepath = '/content/gdrive/My Drive/NLP_FP/Training_Data_Clean.csv'\n","\n","save_directory = '/content/gdrive/My Drive/NLP_FP/Pegasus_Legal_2'\n","\n","predictions_filepath = '/content/gdrive/My Drive/NLP_FP/Pegasus_Legal_2/predictions.csv'\n","\n","wandb_project_name = \"Pegasus_Legal_Summarization_Run_2\"\n","\n","!wandb login ed78357f90c301b50743ea99cb9000752f69a842\n","\n","!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","Tue Jun  1 03:14:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   59C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"932p8NhxeNw4"},"source":["# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.text = self.data.text\n","        self.ctext = self.data.ctext\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        ctext = str(self.ctext[index])\n","        ctext = ' '.join(ctext.split())\n","\n","        text = str(self.text[index])\n","        text = ' '.join(text.split())\n","\n","        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, \n","                                                  pad_to_max_length=True,\n","                                                  return_tensors='pt',\n","                                                  truncation=True)\n","        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, \n","                                                  pad_to_max_length=True,\n","                                                  return_tensors='pt',\n","                                                  truncation=True)\n","\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7d76XO5i3H_"},"source":["def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in enumerate(loader, 0):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone().detach()\n","        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","        \n","        # Changed this code from lm_labels to labels; lm_labels is deprecated - https://github.com/priya-dwivedi/Deep-Learning/issues/137\n","        # outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n","        loss = outputs[0]\n","        \n","        if _%10 == 0:\n","            wandb.log({\"Training Loss\": loss.item()})\n","\n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # xm.optimizer_step(optimizer)\n","        # xm.mark_step()\n","        return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j9TNdHlQ0CLz"},"source":["def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=250, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0db359f52adc4bbe948958097f43f706","9c323a02c7ea49aa8bcec4db59c0bac7","b5f6fecc857247f398b02f6c273fefa8","ffdf7a9940c24c4d9f71b0aab506f138","2375a1ce655a42fda70975ba382b5ed6","3e76fac801d64e828c43b5bd30c3d0e6","576ad34ca48146598da48bb190efa4c1","1d57ff39389c4e44a0d0a8cf145d0f1f","390bb3b38df14966a95160af160d2050","194c61711e354b23b6868dee03137fe9","c65098b7efd84aa2b94335c3458abc5c","08e1c3beaccc4a43b6f09cc30a2190fc","030f3ce3cac44750abbd38195f3aca2f","6e8ad7ad342c4d909b9ed38dab03f000","953e7aaa02c649c887c52b2fa74839bf","9b31a1a7e185456e976d38a9abd5e7de","fc0010509409426fb17e941d56019b76","edf49e2810ae45e3a14cf82fc0920ed1","2205be2c4e7c47628a74a3c1487f1684","4e786a3698204973a28221a28dc36540","f1922313dd4648f08b6991e5c967905e","ba84786fa17b44edaebb2de50503cd1c","d8350cf8958240ffba427e5f4d67b961","6c79ab82798248db8d827d5c0697e5e6","36e2f9d172f54aa199bf6fc94c3dc164","d10be282455b417caf3cc0cd610ed4ac","0c9c587ca3cc4b1f8a28bb80ad9eb512","073e69534b4f42de8823e0e7c8dd3f55","76856ac9acc54a2cbc37dd5e53a9de38","a9d51d743aaa48b2971f7ef6a8bea9db","aee5e212734a446d928228fc05eec2c9","c0f99d805790466384f511457353d02e","8e1bef79e65a48e385b74990b9c0b1de","0e9c31472af94dc0af3bdbd8ca2640ca","8a40afcde00d43b0bb81ca30c3414f25","64806cc694a649b7a40a289ccffdaee8","4fe22acd343f445da93ab3e91e34b1ec","2573ef84624e4b05beb104ab8819c709","f21a0e72d8ff4ec288c1f0766c075c34","77968d3458b640a882350f290b7bd41e","63bc6624ab404bf7949a2a31dcdbe9c7","688e9dbac19842748dbe7d8edbe8ff81","0a72c08ec2914047bad85b36bbcb96de","b423f4f655784b9cb3ed7c1d89d65f33","e0b4114b03f246b09813df01f3d3d0f0","c6def35e90c1404da021b40fc09ef93d","8652d66f21364a7386715df31ac8e9de","7364e3848b234801be85bf19070f3b29"]},"id":"ZtNs9ytpCow2","scrolled":false,"executionInfo":{"status":"ok","timestamp":1622000317927,"user_tz":240,"elapsed":126,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"b4097963-8434-4e1d-a788-02f1a766c56d"},"source":["def main():\n","    # WandB – Initialize a new run\n","    wandb.init(project=wandb_project_name)\n","\n","    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n","    # Defining some key variables that will be used later on in the training  \n","    config = wandb.config          # Initialize config\n","    config.TRAIN_BATCH_SIZE = 1    # input batch size for training (default: 64)\n","    config.VALID_BATCH_SIZE = 1    # input batch size for testing (default: 1000)\n","    config.TRAIN_EPOCHS = 1        # number of epochs to train (default: 10)\n","    config.VAL_EPOCHS = 1 \n","    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","    config.SEED = 42               # random seed (default: 42)\n","    config.MAX_LEN = 512\n","    config.SUMMARY_LEN = 250 \n","\n","    # Set random seeds and deterministic pytorch for reproducibility\n","    torch.manual_seed(config.SEED) # pytorch random seed\n","    np.random.seed(config.SEED) # numpy random seed\n","    torch.backends.cudnn.deterministic = True\n","\n","    # tokenzier for encoding the text\n","    tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n","\n","    # Importing and Pre-Processing the domain data\n","    # Selecting the needed columns only. \n","    # Adding the summarzie text in front of the text. \n","    # This is to format the dataset similar to how T5 model was trained for summarization task. \n","    df = pd.read_csv(filepath, encoding='latin-1')\n","    df = df[['text','ctext']]\n","    df.ctext = 'summarize: ' + df.ctext\n","    print(df.head())\n","\n","    \n","    # Creation of Dataset and Dataloader\n","    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n","    train_size = 0.8\n","    split = int(train_size * df.shape[0])\n","    #train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n","    train_dataset = df.iloc[:split]\n","    val_dataset = df.iloc[split:]\n","    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","    train_dataset = train_dataset.reset_index(drop=True)\n","\n","    print(\"FULL Dataset: {}\".format(df.shape))\n","    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n","\n","\n","    # Creating the Training and Validation dataset for further creation of Dataloader\n","    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","    # Defining the parameters for creation of dataloaders\n","    train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","    val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n","    training_loader = DataLoader(training_set, **train_params)\n","    val_loader = DataLoader(val_set, **val_params)\n","\n","\n","    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n","    # Further this model is sent to device (GPU/TPU) for using the hardware.\n","    model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\")\n","    model = model.to(device)\n","\n","    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n","    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","\n","    # Log metrics with wandb\n","    wandb.watch(model, log=\"all\")\n","    # Training loop\n","    print('Initiating Fine-Tuning for the model on our dataset')\n","\n","    for epoch in range(config.TRAIN_EPOCHS):\n","    #    train(epoch, tokenizer, model, device, training_loader, optimizer)\n","        fine_tuned_model = train(epoch, tokenizer, model, device, training_loader, optimizer)\n","\n","\n","    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n","    # Saving the dataframe as predictions.csv\n","    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n","    for epoch in range(config.VAL_EPOCHS):\n","        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","        final_df.to_csv(predictions_filepath)\n","        print('Output Files generated for review')\n","    \n","    wandb.finish()\n","    return fine_tuned_model\n","\n","if __name__ == '__main__':\n","    fine_tuned_model = main()\n","    fine_tuned_model.save_pretrained(save_directory=save_directory)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mogk01\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.30<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">playful-energy-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2\" target=\"_blank\">https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2</a><br/>\n","                Run page: <a href=\"https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2/runs/2hgswxnw\" target=\"_blank\">https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2/runs/2hgswxnw</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210526_030753-2hgswxnw</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0db359f52adc4bbe948958097f43f706","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1328.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"390bb3b38df14966a95160af160d2050","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc0010509409426fb17e941d56019b76","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1341.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36e2f9d172f54aa199bf6fc94c3dc164","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1508.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","                                                text                                              ctext\n","0  3 Chairmans statement Oxford Universitys Said ...  summarize:  4MEGGITT PLC REPORT AND ACCOUNTS 2...\n","1  Chairmans statement Growing the Group Its been...  summarize:  6 MEGGITT PLC          REPORT AND ...\n","2  Chairmans statement I am pleased to report our...  summarize:  Chief Executives reviewDivestments...\n","3  GROUP OVERVIEW Chairmans statement 2014 has be...  summarize:  STRATEGIC REPORT Chief Executive O...\n","4  2 Metalrax Group PLC Engineering specialists I...  summarize:  CHIEF EXECUTIVES REVIEW6 Metalrax ...\n","FULL Dataset: (1528, 2)\n","TRAIN Dataset: (1222, 2)\n","TEST Dataset: (306, 2)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e1bef79e65a48e385b74990b9c0b1de","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2283841687.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Initiating Fine-Tuning for the model on our dataset\n"],"name":"stdout"},{"output_type":"stream","text":["The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0, Loss:  9.35388469696045\n","Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n","Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Output Files generated for review\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 353<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63bc6624ab404bf7949a2a31dcdbe9c7","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.07MB of 0.07MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/wandb/run-20210526_030753-2hgswxnw/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/wandb/run-20210526_030753-2hgswxnw/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>Training Loss</td><td>9.35388</td></tr><tr><td>_runtime</td><td>1814</td></tr><tr><td>_timestamp</td><td>1622000287</td></tr><tr><td>_step</td><td>1</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>Training Loss</td><td>▁</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">playful-energy-7</strong>: <a href=\"https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2/runs/2hgswxnw\" target=\"_blank\">https://wandb.ai/ogk01/Pegasus_Legal_Summarization_Run_2/runs/2hgswxnw</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"_1O2E492q-E_"},"source":["# End of Model Fine Tuning"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRs350Zrq-E_"},"source":["### Review Output"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"IVIbSgj7q-E_","executionInfo":{"status":"ok","timestamp":1622517269814,"user_tz":240,"elapsed":2463,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"7aedb6a7-c783-430a-94d5-c66de6c8b21b"},"source":["training_data = pd.read_csv(filepath)\n","predictions_sample = pd.read_csv(predictions_filepath)\n","predictions_sample.head(10)\n","predictions_sample.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Generated Text</th>\n","      <th>Actual Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>FirstGroup's 2013 Annual Report and Accounts f...</td>\n","      <td>02 FirstGroup Annual Report and Accounts 2013 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>The annual report and accounts for the year en...</td>\n","      <td>2 FirstGroup Annual Report and Accounts 2014 C...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A further weakening of the US dollar reduced t...</td>\n","      <td>04 FKI plc Chairmans statement Gordon Page Cha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>In 2007 Flomerics invested in expanding its sa...</td>\n","      <td>CHAIRMANS STATEMENT During 2007 there was good...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>The Board of Directors of Energetix Group plc ...</td>\n","      <td>2 Energetix Group plc Group Financial Statemen...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>The Board is pleased with the successful trans...</td>\n","      <td>2 E n e r ge t i x Group plc Group Financial S...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>The Group has achieved both revenue growth and...</td>\n","      <td>5 Business review In my first annual report as...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>The 2004 Financial Sector Technology Awards na...</td>\n","      <td>4 Focus Solutions Group plc Annual Report &amp; Ac...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>The audited financial results for the year end...</td>\n","      <td>4 Focus Solutions Group plc Annual Report &amp; Ac...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>The group again achieved record sales andprofi...</td>\n","      <td>Introduction I am pleased to be able to report...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                        Actual Text\n","0           0  ...  02 FirstGroup Annual Report and Accounts 2013 ...\n","1           1  ...  2 FirstGroup Annual Report and Accounts 2014 C...\n","2           2  ...  04 FKI plc Chairmans statement Gordon Page Cha...\n","3           3  ...  CHAIRMANS STATEMENT During 2007 there was good...\n","4           4  ...  2 Energetix Group plc Group Financial Statemen...\n","5           5  ...  2 E n e r ge t i x Group plc Group Financial S...\n","6           6  ...  5 Business review In my first annual report as...\n","7           7  ...  4 Focus Solutions Group plc Annual Report & Ac...\n","8           8  ...  4 Focus Solutions Group plc Annual Report & Ac...\n","9           9  ...  Introduction I am pleased to be able to report...\n","\n","[10 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"execute_result","data":{"text/plain":["(306, 3)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"g_HKfLtOvVwS"},"source":["def shap_summary_values(model, tokenizer, text):\n","    text_list = []\n","    text_list.append(text)\n","    explainer = shap.Explainer(model, tokenizer)\n","    shap_values = explainer(text_list)\n","    display(shap.plots.text(shap_values))\n","    return\n","\n","def view_summary_comparisons(i, predictions_sample=predictions_sample):\n","    summary1 = predictions_sample[\"Generated Text\"].iloc[i]\n","    print(summary1, '\\n')\n","    print(len(predictions_sample[\"Generated Text\"].iloc[i].split()), '\\n')\n","    summary2 = predictions_sample[\"Actual Text\"].iloc[i]\n","    print(summary2, '\\n')\n","    print(len(predictions_sample[\"Actual Text\"].iloc[i].split()))\n","    return\n","\n","def get_training_data(i, tokens, training_data=training_data):\n","    print(training_data.loc[i])\n","    print(training_data.loc[i, \"ctext\"])\n","    print(\"\\n\")\n","    len(training_data.loc[i, \"ctext\"].split())\n","    print(\"\\n\")\n","    text = ' '.join(training_data.loc[i, \"ctext\"].split()[0:tokens])\n","    print(\"\\n\")\n","    len(text.split())\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Go8t5QBvvX1U","executionInfo":{"status":"ok","timestamp":1622000621497,"user_tz":240,"elapsed":122772,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"2b80aa41-7865-4ebe-842f-7d4a8cd1f005"},"source":["fine_tuned_model = AutoModelForSeq2SeqLM.from_pretrained(save_directory).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n","print(fine_tuned_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PegasusForConditionalGeneration(\n","  (model): PegasusModel(\n","    (shared): Embedding(96103, 1024, padding_idx=0)\n","    (encoder): PegasusEncoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (12): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (13): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (14): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (15): PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): PegasusDecoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (12): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (13): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (14): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (15): PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CcP3bycKq-FB"},"source":["#### Shap Values"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DriVsjiLvYXN","executionInfo":{"status":"ok","timestamp":1622000668722,"user_tz":240,"elapsed":89,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"00980b0f-8976-4228-e8e6-c6baeddec6fd"},"source":["view_summary_comparisons(0)\n","text1 = get_training_data(1222, tokens=300, training_data=training_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FirstGroup's 2013 Annual Report and Accounts for the year ending 31 December 2013 published today. The full text of the report is available on the company's website at www.firstgroup.com. The annual report also includes a summary of the key strategic developments that have taken place since the last report. The CEO highlights the significant progress made in the Group's transformation plan, which has led to the creation of a world-class transport operator with a diverse portfolio of assets across North America and Europe. In May 2013, the Board announced plans to raise approximately 615 million pounds through a rights issue. This will remove the constraints of the Company's current balance sheet and provide the flexibility to continue its transformation plans and invest to create sustainable, long term value. We aim to increase Group revenue (excluding UK Rail) at a faster rate than the economies we serve, improve margins in First Student and UK Bus1 to double digit levels, and achieve a post-tax return on capital employed (ROCE) in the 10% to 12% range. As the business performance improves, we aim to re-establish a progressive dividend policy to target 2.0 to 2.5 times dividend cover. \n","\n","194 \n","\n","02 FirstGroup Annual Report and Accounts 2013 Chairmans statement As we continue to manage in a climate of uncertainty, we have taken significant steps this year to enhance our flexibility and strengthen the Group for the future. In a sector that is a key enabler of economic development, the Groups diverse portfolio offers an attractive platform for sustainable growth. During the year we continued to take action to mitigate the effects of prolonged economic weakness and to place the business on a firmer footing to continue to invest for the future and deliver improved growth and returns. The Group has grown rapidly over the last 20 years through a combination of acquisition, organic growth and contract wins, and we have established a broad-based portfolio of market leading transport \n","\n","128\n","Unnamed: 0                                                          1222\n","Original_Filename_x                                        6065_308036_2\n","Gold_Filename                                              6065_308035_1\n","Document                                                            6065\n","ctext                   04 FirstGroup Annual Report and Accounts 2013...\n","text                   02 FirstGroup Annual Report and Accounts 2013 ...\n","Name: 1222, dtype: object\n"," 04 FirstGroup Annual Report and Accounts 2013Chief Executives strategic reviewTim OToole Chief ExecutiveOur services help to create strong, vibrant and sustainable local economies and our opportunity is to be the provider of choice for our customers and communities. We are the largest transport operator in the UK and North America and each day, every one of our 120,000 employees works hard to deliver vitally important services for our passengers. During the last year more than 2.5 billion passengers relied on us to get to work,  to education, to visit family and friends and for much more. In May of this year, Martin Gilbert announced his intention to stand down as Chairman, once a successor has been identified. On behalf of the Board and our employees, I would like to pay tribute to Martin and thank him for his outstanding contribution to the Company.  As Chairman and a founder, his vision and drive have led the transformation of the Group, and under his stewardship the business has grown to become one of the worlds leading transport operators.Our opportunityOur objective is to provide sustainable, integrated transport services that are safe, reliable and meet the needs of the customers and the communities we serve. We have established a diverse portfolio of assets in a sector which is a key enabler of economic growth. Effective transport links are essential to the prosperity of any economy, and whilst the needs of any one local or regional community may be different, as we look ahead, the unrelenting move towards urbanisation means that we can be certain that congestion will be a feature of the future. It is companies like ours with the necessary breadth and scale, and collective expertise and capability spanning two continents, that will be able to provide efficient solutions to congestion. Capital structureIn May 2013 we announced a rights issue to raise approximately  615m, which will remove the constraints of our current balance sheet and provide the necessary flexibility to continue our transformation plans and invest to create sustainable, long term value. The decisions we have taken this year will position the Group to deliver improved growth, and return us to a profile of consistent financial returns and cash generation. Over the next four years we aim to increase Group revenue (excluding UK Rail) at a faster rate than the economies we serve, improve margins in First Student and UK Bus1  to double digit levels, and achieve a post-tax return on capital employed (ROCE) in the 10% to 12% range. We aim to maintain  an investment grade credit rating and appropriate balance sheet liquidity and headroom and, as the business performance improves, to re-establish a progressive dividend policy to target 2.0 to 2.5 times dividend cover.Future outlookThe actions we are taking will create a more robust company and one that is better placed to face its challenges, deliver on its promises and take advantage of future opportunities. As a result I believe that we are in a stronger position now with greater clarity and confidence in our wayforward.1 On a post-IAS 19 basis. The estimated impact of IAS 19 is set out on page 39.Committed to our customers  We keep our customers at the heart of everything we do.Dedicated to safety  Always front of mind, safety is our way of life.Supportive of each other  We trust each other to deliver and work to help one another succeed.Accountable for performance  Every decision matters, we do the right thing to achieve our goals.Setting the highest standards  We want to be the best, continually seeking a better way to do things.Our vision is to provide solutions for  an increasingly congested world...  keeping people moving and  communities prospering.Our vision and values Overview05 FirstGroup Annual Report and Accounts 2013Actions taken this year Future prioritiesThis year has been a significant one for the  Group as we moved ahead with our plans for our future development. Our business improvement programmes are at different stages across each ofour divisions, but over this year we have prioritisedthe following areas: While we are pleased with progress in the year, significant opportunities remain ahead of us. Over the next four years, we intend to invest approximately 1 .6bn across the Group to continue our transformation programmes and take advantage of growth opportunities. The key priorities in delivering our plans and generating long term, sustainable value forshareholders and our other stakeholders include: First Student We are reforming the operating model to create a more efficient cost structure through improving labour productivity, streamlining systems to reduce bureaucracy, standardising operating procedures and applying best practice. We are expanding  the use of innovative technology, reducing maintenance costs  through uniform practices and reducing fuel costs through enhanced driver training.To continue to execute the ongoing recovery plan by improving operational efficiency with a view to targeting double digit operating margins in the medium term, including by ultimately driving up  our contract retention rates above 90%, taking advantage of opportunities to win new contracts as state authorities and school boards continue to outsource their student bus services, and returning to a selective in-fill acquisition strategy to enhance growth,  at the appropriate levels and time. First Transit We have strengthened our core business units in First Transit, anddisposed of non-core operations during the year. We are seeing a steady pipeline of new contract wins including additional paratransit services and, going forward, we plan to increase our focus on higher growth operations such as our shuttle bus business. We are also placing more emphasis on technological innovation in the division.To continue to achieve strong growth and maintain operating margins while investing to take advantage of key outsourcing opportunities, including the expansion of our shuttle bus operations, particularly on university campuses and in the Canadian oil fields. Greyhound We have significantly transformed Greyhounds operating model tocreate a more flexible and agile business, including through improvements in technology, right sizing and relocating terminals, purchasing new vehicles and refurbishing our existing fleet. We are expanding our Greyhound Express services, building on the inherent strength of our unique national network, as well as developing bespoke brands for niche markets.We will invest in infrastructure and IT, including new reservation and ticketing systems, to drive operational efficiencies, facilitate better yield management and thereby seek to achieve growth in excess of GDP , as we have achieved in BoltBus and Greyhound Express. Further capital expenditure will also be made to renew and refurbish the Greyhound fleet and to continue to fund the addition of new routes and services. UK Bus During the year we rebalanced our UK Bus portfolio through a programme of selected business and asset disposals. We are improving efficiency by standardising our maintenance and operating procedures, investing in our bus fleet and adjusting the commercial model to be more responsive locally and to enhance patronage growth.To improve operating margins, on a post-IAS 19, basis to double digit levels in the medium term by continuing our depot transformation programme, network redesign plans, reducing the fleet age to be closer in line with our peers, as well as improving our information provision and smart ticketing capabilities to support volume growth. UK Rail We continue to focus on operating performance across all of our  UK Rail operations, including prioritising the introduction of new smart ticketing and passenger information technology. We are working closely with our partners to deliver infrastructure and capacity upgrades. Contract extensions are being negotiated for two of our franchises, and we remain committed to maintaining our leading position in the rail market as the DfTs franchising process restarts. Ensuring our management expertise and capital strength continues to support our plans to participate in a range of future franchise competitions and tenders and maintain our market leading position.\n","\n","\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627,"referenced_widgets":["60ae3c9f6bda4c6a86e624bde2ab7eaf","fc2dff9dbac543af9d7e990e83ba9392","42a7eca621384ae0907b2414e9ac69fb","adee1dec79fa4f65a2cd7c09bd4379c7","8813d62880be42acbe1a83e55a7c2a44","e14d8d26d77f40f4847e039593803ae7","89f9de024e5442ffb494c1cbb3d1757c","d8f13840fb064839a0511a6a85f730db"],"output_embedded_package_id":"1jUdI6F5Tp3zBeDtIvOIlmX5wbcwBxxV8"},"id":"yCNFPViYvY8j","executionInfo":{"status":"ok","timestamp":1622000774509,"user_tz":240,"elapsed":47543,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"d4c51da5-a5cd-4b2c-84d3-b50edf7fd143"},"source":["shap_summary_values(fine_tuned_model, tokenizer, text1)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970,"referenced_widgets":["5166075291b74bfc9748e19c5bec45bc","abd4e0f16b374b51ae0a2a25ae04b2d6","ed208c807e2141b3b5899d61bd00f948","aabde2074eba41b5bf01658bc1e06f62","a5999242b67c41e787309bd95d07a461","ddd4ef28407647ff967c7d71d494520a","443f319497f040f7beb141cc3b673f14","0f86a48609a444f0b79653a80a5437ae"],"output_embedded_package_id":"1PZCIH5KcrZllGbwgW15UYGwtBivR3owd"},"id":"1jZoGKD3yBHL","executionInfo":{"status":"ok","timestamp":1622000871449,"user_tz":240,"elapsed":45462,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"4c0699d9-eac9-441f-c8fe-c56e97f31d5c"},"source":["text2 = get_training_data(1222, tokens=400, training_data=training_data)\n","shap_summary_values(fine_tuned_model, tokenizer, text2)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Id71IWn_q-FA"},"source":["#### ROUGE Score Calculation"]},{"cell_type":"code","metadata":{"id":"Rf3jP0P_qc0L","executionInfo":{"status":"ok","timestamp":1622517284929,"user_tz":240,"elapsed":100,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}}},"source":["# Rouge Score Calculation\n","\n","def rouge_scores(gen_summary_list, actual_summary_list, metric='recall'):\n","    rouge1_scores = []\n","    rougeL_scores = []\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n","    for i in range(0, len(gen_summary_list)):\n","        scores = scorer.score(actual_summary_list[i], gen_summary_list[i])\n","        if metric == 'recall':\n","            rouge1_scores.append(scores['rouge1'][1])\n","            rougeL_scores.append(scores['rougeL'][1])\n","        elif metric == 'precision':\n","            rouge1_scores.append(scores['rouge1'][0])\n","            rougeL_scores.append(scores['rougeL'][0])\n","        elif metric == 'fmeasure':\n","            rouge1_scores.append(scores['rouge1'][2])\n","            rougeL_scores.append(scores['rougeL'][2])     \n","    print(\"Average Rouge-1\", str(metric), \":\", round(np.mean(rouge1_scores), 2))\n","    print(\"Average Rouge-L\", str(metric), \":\", round(np.mean(rougeL_scores), 2))\n","    return"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0Dg1R_VqiDL","executionInfo":{"status":"ok","timestamp":1622517299178,"user_tz":240,"elapsed":12968,"user":{"displayName":"Omkar Kharkar","photoUrl":"","userId":"01594415506940449395"}},"outputId":"8ae24aac-5f74-410c-fc2b-e8b59d05a75f"},"source":["rouge_scores(list(predictions_sample[\"Generated Text\"]), list(predictions_sample[\"Actual Text\"]), metric='recall')\n","rouge_scores(list(predictions_sample[\"Generated Text\"]), list(predictions_sample[\"Actual Text\"]), metric='precision')\n","rouge_scores(list(predictions_sample[\"Generated Text\"]), list(predictions_sample[\"Actual Text\"]), metric='fmeasure')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Average Rouge-1 recall : 0.31\n","Average Rouge-L recall : 0.16\n","Average Rouge-1 precision : 0.37\n","Average Rouge-L precision : 0.19\n","Average Rouge-1 fmeasure : 0.33\n","Average Rouge-L fmeasure : 0.17\n"],"name":"stdout"}]}]}